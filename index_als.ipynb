{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, SQLContext, Row\n",
    "from pyspark.sql.types import StructType, StructField, ArrayType, FloatType, IntegerType\n",
    "import pyspark.sql.functions as f\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "warehouse_location = \"hdfs://m1.local.br:9000/user/hive/warehouse\"\n",
    "hive_metastore_uri = \"thrift://m1.local.br:9083\"\n",
    "defaultFS = \"hdfs://m1.local.br:9000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Conectando ao Hive com PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-UFO3D9P:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Machine Learning - MovieLens dataset</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x293f938d6d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .config('spark.ui.port', '4040') \\\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Machine Learning - MovieLens dataset\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_location) \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", defaultFS) \\\n",
    "    .config(\"hive.metastore.uris\", hive_metastore_uri) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.refreshByPath(warehouse_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URI do Metastore do Hive: thrift://m1.local.br:9083\n",
      "Endereço do Hadoop (HDFS): hdfs://m1.local.br:9000\n"
     ]
    }
   ],
   "source": [
    "print(\"URI do Metastore do Hive:\", spark.conf.get(\"hive.metastore.uris\"))\n",
    "print(\"Endereço do Hadoop (HDFS):\", spark.conf.get(\"spark.hadoop.fs.defaultFS\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|current_user()|\n",
      "+--------------+\n",
      "| Vinicius Luiz|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualizando o nome do usuário\n",
    "tables = spark.sql(\"SELECT current_user()\")\n",
    "tables.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se conectando ao banco default\n",
    "spark.sql(\"USE default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+-----------+\n",
      "|namespace|        tableName|isTemporary|\n",
      "+---------+-----------------+-----------+\n",
      "|  default|    genome_scores|      false|\n",
      "|  default|genome_scores_tmp|      false|\n",
      "|  default|      genome_tags|      false|\n",
      "|  default|  genome_tags_tmp|      false|\n",
      "|  default|            links|      false|\n",
      "|  default|        links_tmp|      false|\n",
      "|  default|           movies|      false|\n",
      "|  default|       movies_tmp|      false|\n",
      "|  default|          ratings|      false|\n",
      "|  default|      ratings_tmp|      false|\n",
      "|  default|             tags|      false|\n",
      "|  default|         tags_tmp|      false|\n",
      "+---------+-----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualizando as tabelas no database default\n",
    "tables = spark.sql(\"SHOW tables\")\n",
    "tables.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_COUNT = '''\n",
    "select count(1)       as qtd_linhas\n",
    "    , 'genome_scores' as table_name\n",
    "  from genome_scores\n",
    "union all\n",
    "select count(1)       as qtd_linhas\n",
    "    , 'genome_tags'   as table_name\n",
    "  from genome_tags\n",
    "union all\n",
    "select count(1)       as qtd_linhas\n",
    "    , 'movies'        as table_name\n",
    "  from movies\n",
    "union all\n",
    "select count(1)       as qtd_linhas\n",
    "    , 'ratings'       as table_name\n",
    "  from ratings\n",
    "union all\n",
    "select count(1)       as qtd_linhas\n",
    "    , 'tags'          as table_name\n",
    "  from tags\n",
    "union all\n",
    "select count(1)       as qtd_linhas\n",
    "    , 'links'         as table_name\n",
    "  from links\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|qtd_linhas|table_name   |\n",
      "+----------+-------------+\n",
      "|18472128  |genome_scores|\n",
      "|1128      |genome_tags  |\n",
      "|86537     |movies       |\n",
      "|33832162  |ratings      |\n",
      "|2328315   |tags         |\n",
      "|86537     |links        |\n",
      "+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movies = spark.sql(SQL_COUNT)\n",
    "df_movies.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Definindo amostragem\n",
    "O modelo ALS será treinado apenas com filmes que têm mais de **100 avaliações**. Isso pode ser importante para garantir que os filmes usados no treinamento do modelo tenham recebido um número suficiente de avaliações para gerar recomendações mais robustas e significativas.\n",
    "\n",
    "Os números fornecidos indicam a distribuição do número de avaliações para os filmes:\n",
    "\n",
    "- O dataset contém **83.239** filmes.\n",
    "- **17.916** filmes contêm apenas 1 avaliação.\n",
    "- **10.161** filmes contêm apenas 2 avaliações.\n",
    "- **55.162** filmes contêm 3 avaliações ou mais.\n",
    "- **43.873** filmes contêm 5 avaliações ou mais.\n",
    "- **32.021** filmes contêm 10 avaliações ou mais.\n",
    "- **16.116** filmes contém 50 avaliações ou mais.\n",
    "- **12.253** filmes contêm 100 avaliações ou mais.\n",
    "- **6.929** filmes contêm mais avaliações do que a média (406)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Realizando a Hiperparametrização do modelo ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12253"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtd_min_ratings = 100\n",
    "\n",
    "SQL_AMOSTRAGEM = '''\n",
    "SELECT m.movieid\n",
    "     , count(1)      as qtd_ratings\n",
    "  FROM ratings r\n",
    "  JOIN movies m\n",
    "    ON r.movieid = m.movieid\n",
    " GROUP BY m.movieid\n",
    " HAVING count(1) >= {qtd_min_ratings}\n",
    "'''\n",
    "\n",
    "df_movies_sample = spark.sql(SQL_AMOSTRAGEM.format(qtd_min_ratings = qtd_min_ratings))\n",
    "df_movies_sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies_sample.createOrReplaceTempView(\"movies_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a biblioteca RegressionEvaluator do PySpark para avaliação de modelos de regressão\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Importando a biblioteca ALS do PySpark para filtragem colaborativa e recomendação\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# Importando a biblioteca TrainValidationSplit do PySpark para realizar validação\n",
    "# Importando também a classe ParamGridBuilder para construir um grid de parâmetros a serem testados durante a validação cruzada\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userid|movieid|rating|\n",
      "+------+-------+------+\n",
      "|9     |474    |4.0   |\n",
      "|22    |106100 |5.0   |\n",
      "|24    |474    |4.5   |\n",
      "|24    |6721   |3.0   |\n",
      "|30    |72011  |4.0   |\n",
      "+------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- userid: long (nullable = true)\n",
      " |-- movieid: long (nullable = true)\n",
      " |-- rating: decimal(10,1) (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33060369"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQL_RATINGS ='''\n",
    "SELECT r.userid\n",
    "     , r.movieid\n",
    "     , r.rating\n",
    " FROM ratings r\n",
    " JOIN movies_sample ms\n",
    "   ON r.movieid = ms.movieid\n",
    "'''\n",
    "\n",
    "ratings = spark.sql(SQL_RATINGS)\n",
    "ratings = ratings.withColumn(\"userid\", f.col(\"userid\").cast(\"long\"))\n",
    "\n",
    "ratings.show(5, truncate=False)\n",
    "ratings.printSchema()\n",
    "ratings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os dados em 70% para o treinamento e 30% para a validação\n",
    "(train, test) = ratings.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um modelo ALS\n",
    "# Parâmetros:\n",
    "# - userCol: Nome da coluna que contém os IDs dos usuários\n",
    "# - itemCol: Nome da coluna que contém os IDs dos itens (por exemplo, filmes)\n",
    "# - ratingCol: Nome da coluna que contém as classificações atribuídas pelos usuários aos itens\n",
    "# - coldStartStrategy: Estratégia para lidar com novos usuários ou itens durante a previsão (\"drop\" irá descartar)\n",
    "# - nonnegative: Se True, restringe os fatores latentes a valores não negativos\n",
    "\n",
    "als = ALS(userCol=\"userid\", itemCol=\"movieid\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\", nonnegative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um grid de parâmetros para hiperparametrização do modelo ALS usando ParamGridBuilder\n",
    "\n",
    "# rank: número de fatores latentes\n",
    "# maxIter: número máximo de iterações\n",
    "# regParam: parâmetro de regularização\n",
    "param_grid = ParamGridBuilder()\\\n",
    "            .addGrid(als.rank, [10, 15, 20])\\\n",
    "            .addGrid(als.maxIter, [5, 10, 15])\\\n",
    "            .addGrid(als.regParam, [0.01, .1, .5])\\\n",
    "            .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo um avaliador para a métrica RMSE (Root Mean Squared Error)\n",
    "\n",
    "# Parâmetros:\n",
    "# - metricName: Nome da métrica a ser avaliada, neste caso, \"rmse\" para o Root Mean Squared Error\n",
    "# - labelCol: Nome da coluna que contém os rótulos reais (neste caso, as classificações atribuídas pelos usuários)\n",
    "# - predictionCol: Nome da coluna que contém as previsões geradas pelo modelo\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um objeto TrainValidationSplit no PySpark para realizar a divisão entre treino e validação durante a validação cruzada\n",
    "\n",
    "# Parâmetros:\n",
    "# - estimator: Estimador a ser validado, neste caso, o modelo ALS que foi criado anteriormente\n",
    "# - estimatorParamMaps: Grid de parâmetros a serem testados durante a validação cruzada\n",
    "# - evaluator: Avaliador a ser usado para avaliar o desempenho do modelo em diferentes configurações\n",
    "\n",
    "train_validation = TrainValidationSplit(\n",
    "    estimator=als,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=evaluator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o modelo\n",
    "model = train_validation.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALSModel: uid=ALS_b76d695af141, rank=20"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtendo o melhor modelo\n",
    "best_model = model.bestModel\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userid|movieid|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|28    |135    |1.0   |2.2751474 |\n",
      "|28    |593    |4.0   |3.7553833 |\n",
      "|28    |2184   |4.0   |3.2852948 |\n",
      "|28    |2559   |3.0   |2.1906624 |\n",
      "|31    |47     |3.0   |2.764629  |\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gerando as previsões\n",
    "predictions = best_model.transform(test)\n",
    "predictions.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliando o modelo\n",
    "rmse = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando que os ratings variam de 0 a 5, o Root Mean Square Error (RMSE) de **0.809221** indica que, em média, as previsões do modelo têm uma discrepância de aproximadamente 0.809221 unidades em relação aos valores reais em uma escala de 0 a 5. O termo \"root\" no RMSE implica que os erros foram primeiro elevados ao quadrado, acentuando a penalização dos erros maiores. A aplicação da raiz quadrada então retorna a métrica à mesma escala dos dados originais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 0.809221\n",
      "Rank = 20\n",
      "MaxIter = 15\n",
      "RegParam = 0.1\n"
     ]
    }
   ],
   "source": [
    "# Mostrando os resultados\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "print(\"Rank = %d\" % best_model.rank)\n",
    "print(\"MaxIter = %d\" % best_model._java_obj.parent().getMaxIter())\n",
    "print(\"RegParam = %g\" % best_model._java_obj.parent().getRegParam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userid|movieid|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|28    |135    |1.0   |2.2751474 |\n",
      "|28    |593    |4.0   |3.7553833 |\n",
      "|28    |2184   |4.0   |3.2852948 |\n",
      "|28    |2559   |3.0   |2.1906624 |\n",
      "|31    |47     |3.0   |2.764629  |\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostrando as previsões\n",
    "predictions.sort('userid', 'rating')\n",
    "predictions.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Gerando recomendações para todos os usuários usando o emlhor modelo obtido após o treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vinicius Luiz\\Desktop\\Scripts\\movie_recommendation_pyspark\\venv\\lib\\site-packages\\pyspark\\sql\\context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Parâmetros:\n",
    "# - best_model: O modelo que apresentou o melhor desempenho após a validação cruzada\n",
    "# - recommendForAllUsers(10): Gerando recomendações para todos os usuários, onde 10 é o número de itens a serem recomendados para cada usuário\n",
    "user_recs = best_model.recommendForAllUsers(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando recomendações para um usuário\n",
    "def get_recommendations_for_user(recs):\n",
    "    # Explodir a coluna de recomendações\n",
    "    df_exploded = recs.select(\"userid\", f.explode(\"recommendations\").alias(\"rec\"))\n",
    "\n",
    "    # Selecionar as colunas desejadas\n",
    "    df_transformed = df_exploded.select(\"rec.movieid\", \"rec.rating\")\n",
    "\n",
    "    # Renomear as colunas\n",
    "    df_transformed = df_transformed.withColumnRenamed(\"rec.movieid\", \"movieid\") \\\n",
    "                                   .withColumnRenamed(\"rec.rating\", \"rating\")\n",
    "\n",
    "    return df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|userid|recommendations                                                                                                                                                                               |\n",
      "+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1     |[{318, 4.202657}, {182723, 4.170433}, {356, 4.1683593}, {1035, 4.163223}, {115969, 4.160298}, {364, 4.1588306}, {88125, 4.15752}, {176887, 4.1508374}, {159817, 4.1487494}, {4896, 4.1294866}]|\n",
      "+------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "root\n",
      " |-- userid: integer (nullable = false)\n",
      " |-- recommendations: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- movieid: integer (nullable = true)\n",
      " |    |    |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gerando recomendações pro usuário 1\n",
    "\n",
    "user_1 = user_recs.filter(\"userid = 1\")\n",
    "\n",
    "user_1.show(truncate = False)\n",
    "user_1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recomendação final de 10 filmes para o usuário 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|movieid|rating   |\n",
      "+-------+---------+\n",
      "|318    |4.202657 |\n",
      "|182723 |4.170433 |\n",
      "|356    |4.1683593|\n",
      "|1035   |4.163223 |\n",
      "|115969 |4.160298 |\n",
      "|364    |4.1588306|\n",
      "|88125  |4.15752  |\n",
      "|176887 |4.1508374|\n",
      "|159817 |4.1487494|\n",
      "|4896   |4.1294866|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_1_transformed = get_recommendations_for_user(user_1)\n",
    "user_1_transformed.show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Definindo o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender():\n",
    "    '''\n",
    "Root Mean Squared Error (RMSE) on test data = 0.809221\n",
    "Rank = 20\n",
    "MaxIter = 15\n",
    "RegParam = 0.1\n",
    "    '''\n",
    "    def __init__(self, rank: int = 20, maxIter: int = 15, regParam: float = 0.1):\n",
    "        self.model = None\n",
    "        self.ratings = None\n",
    "\n",
    "        self.rank = rank\n",
    "        self.maxIter = maxIter\n",
    "        self.regParam = regParam\n",
    "\n",
    "        self.schema = StructType([\n",
    "            StructField(\"userid\", IntegerType()),\n",
    "            StructField(\"recommendations\", ArrayType(StructType([\n",
    "                StructField(\"movieid\", IntegerType()),\n",
    "                StructField(\"rating\", FloatType())\n",
    "            ])))\n",
    "        ])\n",
    "\n",
    "    def prepare_data(self, sql: str):\n",
    "        self.ratings = spark.sql(sql)\n",
    "        self.ratings = ratings.withColumn(\"userid\", f.col(\"userid\").cast(\"long\"))\n",
    "    \n",
    "    def fit(self):\n",
    "        als = ALS(userCol=\"userid\", itemCol=\"movieid\", ratingCol=\"rating\",\n",
    "                  coldStartStrategy=\"drop\", nonnegative=True,\n",
    "                  rank=self.rank, maxIter=self.maxIter, regParam=self.regParam)\n",
    "\n",
    "        self.model = als.fit(self.ratings)\n",
    "    \n",
    "    def mount_user_ratings(self, userid: int, user_ratings: list):\n",
    "        user = [\n",
    "            (userid, user_ratings)\n",
    "        ]\n",
    "        return spark.createDataFrame(user, schema=self.schema)\n",
    "    \n",
    "    def recommendForUserSubset(self, user_ratings, numItems: int):\n",
    "        recs = self.model.recommendForUserSubset(user_ratings, numItems=numItems)\n",
    "\n",
    "        df_exploded = recs.select(\"userid\", f.explode(\"recommendations\").alias(\"rec\"))\n",
    "\n",
    "        df_transformed = df_exploded.select(\"rec.movieid\", \"rec.rating\")\n",
    "\n",
    "        df_transformed = df_transformed.withColumnRenamed(\"rec.movieid\", \"movieid\") \\\n",
    "                                        .withColumnRenamed(\"rec.rating\", \"rating\")\n",
    "\n",
    "        return df_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 - Exemplo de uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mês e Ano máximo\n",
    "# extract(year from r.rating_date) = 2023\n",
    "# extract(month from r.rating_date) = 7\n",
    "\n",
    "SQL_RATINGS = ''' \n",
    "WITH movies_sample AS (\n",
    "    SELECT m.movieid\n",
    "         , count(1)      as qtd_ratings\n",
    "      FROM ratings r\n",
    "      JOIN movies m\n",
    "        ON r.movieid = m.movieid\n",
    "    GROUP BY m.movieid\n",
    "    HAVING count(1) >= 100\n",
    ")\n",
    "SELECT r.userid\n",
    "     , r.movieid\n",
    "     , r.rating\n",
    " FROM ratings r\n",
    " JOIN movies_sample ms\n",
    "   ON r.movieid = ms.movieid\n",
    "WHERE 1=1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = Recommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender.prepare_data(SQL_RATINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| movieid | title | year | genres |\n",
    "|---------|-------|------|--------|\n",
    "| 4896 | Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001) | 2001 | [Adventure, Children, Fantasy] |\n",
    "| 5816 | Harry Potter and the Chamber of Secrets (2002) | 2002 | [Adventure, Fantasy] |\n",
    "| 8368 | Harry Potter and the Prisoner of Azkaban (2004) | 2004 | [Adventure, Fantasy, IMAX] |\n",
    "| 40815 | Harry Potter and the Goblet of Fire (2005) | 2005 | [Adventure, Fantasy, Thriller, IMAX] |\n",
    "| 54001 | Harry Potter and the Order of the Phoenix (2007) | 2007 | [Adventure, Drama, Fantasy, IMAX] |\n",
    "| 69844 | Harry Potter and the Half-Blood Prince (2009) | 2009 | [Adventure, Fantasy, Mystery, Romance, IMAX] |\n",
    "| 81834 | Harry Potter and the Deathly Hallows: Part 1 (2010) | 2010 | [Action, Adventure, Fantasy, IMAX] |\n",
    "| 88125 | Harry Potter and the Deathly Hallows: Part 2 (2011) | 2011 | [Action, Adventure, Drama, Fantasy, Mystery, IMAX] |\n",
    "| 186777 | The Greater Good - Harry Potter Fan Film (2013) | 2013 | [Action, Adventure, Fantasy] |\n",
    "| 247038 | Harry Potter: A History Of Magic (2017) | 2017 | [Documentary] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "userid = 1\n",
    "\n",
    "user_ratings = [\n",
    "        (4896, 4.5),\n",
    "        (5816, 3.5),\n",
    "        (8368, 5.0),\n",
    "        (40815, 4.5),\n",
    "        (54001, 3.5),\n",
    "        (69844, 4.0),\n",
    "        (81834, 4.5),\n",
    "        (88125, 5.0),\n",
    "        (186777, 2.0),\n",
    "        (247038, 2.5),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings = recommender.mount_user_ratings(userid, user_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vinicius Luiz\\Desktop\\Scripts\\movie_recommendation_pyspark\\venv\\lib\\site-packages\\pyspark\\sql\\context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "user_recomendations = recommender.recommendForUserSubset(user_ratings, numItems=10)\n",
    "user_recomendations.createOrReplaceTempView(\"user_recomendations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------------------------------------------+----+-----------------------------+\n",
      "|movieid|rating   |title                                     |year|genres                       |\n",
      "+-------+---------+------------------------------------------+----+-----------------------------+\n",
      "|318    |4.5356064|The Shawshank Redemption (1994)           |1994|[Crime, Drama]               |\n",
      "|170705 |4.430924 |Band of Brothers (2001)                   |2001|[Action, Drama, War]         |\n",
      "|356    |4.3958735|Forrest Gump (1994)                       |1994|[Comedy, Drama, Romance, War]|\n",
      "|182723 |4.3930745|Cosmos: A Spacetime Odissey               |null|[(no genres listed)]         |\n",
      "|159817 |4.3702717|Planet Earth (2006)                       |2006|[Documentary]                |\n",
      "|171011 |4.339723 |Planet Earth II (2016)                    |2016|[Documentary]                |\n",
      "|527    |4.329928 |Schindler's List (1993)                   |1993|[Drama, War]                 |\n",
      "|2324   |4.3226223|Life Is Beautiful (La Vita è bella) (1997)|1997|[Comedy, Drama, Romance, War]|\n",
      "|3147   |4.3177595|The Green Mile (1999)                     |1999|[Crime, Drama]               |\n",
      "|1704   |4.294319 |Good Will Hunting (1997)                  |1997|[Drama, Romance]             |\n",
      "+-------+---------+------------------------------------------+----+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SQL_RECOMENDATIONS  = '''\n",
    "SELECT r.movieid\n",
    "     , r.rating\n",
    "     , m.title\n",
    "     , m.year\n",
    "     , m.genres\n",
    "  FROM user_recomendations r\n",
    "  JOIN movies m\n",
    "    ON r.movieid = m.movieid\n",
    "'''\n",
    "\n",
    "spark.sql(SQL_RECOMENDATIONS).show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
